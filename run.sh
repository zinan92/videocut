#!/bin/bash
#
# videocut ä¸€é”®å¤„ç†
#
# ç”¨æ³•: ./run.sh <video.mp4> [whisper_model] [--no-server]
#   whisper_model: tiny/base/small/medium/large (é»˜è®¤ small)
#   --no-server: è·³è¿‡å®¡æ ¸æœåŠ¡å™¨ï¼Œç›´æ¥å‰ªè¾‘
#

set -e

VIDEO_PATH="$1"
MODEL="${2:-small}"
NO_SERVER=false

if [ -z "$VIDEO_PATH" ]; then
  echo "ç”¨æ³•: ./run.sh <video.mp4> [whisper_model] [--no-server]"
  exit 1
fi

# Handle --no-server flag in any position
for arg in "$@"; do
  if [ "$arg" = "--no-server" ]; then
    NO_SERVER=true
  fi
done

if [ ! -f "$VIDEO_PATH" ]; then
  echo "âŒ æ‰¾ä¸åˆ°è§†é¢‘: $VIDEO_PATH"
  exit 1
fi

# Resolve absolute path
VIDEO_PATH="$(cd "$(dirname "$VIDEO_PATH")" && pwd)/$(basename "$VIDEO_PATH")"

SCRIPT_DIR="$(cd "$(dirname "$0")/å‰ªå£æ’­/scripts" && pwd)"
VIDEO_NAME=$(basename "$VIDEO_PATH" .mp4)
DATE=$(date +%Y-%m-%d)
BASE_DIR="$(cd "$(dirname "$0")" && pwd)/output/${DATE}_${VIDEO_NAME}"

echo "ğŸ¬ videocut â€” ä¸€é”®å¤„ç†"
echo "ğŸ“¹ è§†é¢‘: $VIDEO_PATH"
echo "ğŸ“‚ è¾“å‡º: $BASE_DIR"
echo ""

# Step 0: Create flat output dir
mkdir -p "$BASE_DIR"

# Step 1: Extract audio
echo "â•â•â• æ­¥éª¤ 1: æå–éŸ³é¢‘ â•â•â•"
ffmpeg -i "file:$VIDEO_PATH" -vn -acodec libmp3lame -y "$BASE_DIR/1_audio.mp3" 2>/dev/null
echo "âœ… 1_audio.mp3"

# Step 2: Whisper transcribe
# Must cd to BASE_DIR so whisper_transcribe.sh writes volcengine_result.json here
echo ""
echo "â•â•â• æ­¥éª¤ 2: Whisper è½¬å½• (model: $MODEL) â•â•â•"
cd "$BASE_DIR"
"$SCRIPT_DIR/whisper_transcribe.sh" "1_audio.mp3" "$MODEL"
mv "volcengine_result.json" "1_volcengine_result.json"

# Step 3: Generate word-level subtitles
# generate_subtitles.js writes subtitles_words.json to cwd ($BASE_DIR)
echo ""
echo "â•â•â• æ­¥éª¤ 3: ç”Ÿæˆå­—çº§åˆ«å­—å¹• â•â•â•"
node "$SCRIPT_DIR/generate_subtitles.js" "${BASE_DIR}/1_volcengine_result.json"
mv "${BASE_DIR}/subtitles_words.json" "${BASE_DIR}/1_subtitles_words.json"

# Step 4: Analysis
echo ""
echo "â•â•â• æ­¥éª¤ 4: åˆ†æ â•â•â•"

# 2_readable.txt
node -e "
const data = require('${BASE_DIR}/1_subtitles_words.json');
let output = [];
data.forEach((w, i) => {
  if (w.isGap) {
    const dur = (w.end - w.start).toFixed(2);
    if (dur >= 0.5) output.push(i + '|[é™' + dur + 's]|' + w.start.toFixed(2) + '-' + w.end.toFixed(2));
  } else {
    output.push(i + '|' + w.text + '|' + w.start.toFixed(2) + '-' + w.end.toFixed(2));
  }
});
require('fs').writeFileSync('${BASE_DIR}/2_readable.txt', output.join('\n'));
console.log('ğŸ“ 2_readable.txt:', output.length, 'lines');
"

# 2_sentences.txt
node -e "
const data = require('${BASE_DIR}/1_subtitles_words.json');
let sentences = [], curr = { text: '', startIdx: -1, endIdx: -1 };
data.forEach((w, i) => {
  const isLongGap = w.isGap && (w.end - w.start) >= 0.5;
  if (isLongGap) {
    if (curr.text.length > 0) sentences.push({...curr});
    curr = { text: '', startIdx: -1, endIdx: -1 };
  } else if (!w.isGap) {
    if (curr.startIdx === -1) curr.startIdx = i;
    curr.text += w.text;
    curr.endIdx = i;
  }
});
if (curr.text.length > 0) sentences.push(curr);
const lines = sentences.map((s, i) => i + '|' + s.startIdx + '-' + s.endIdx + '|' + s.text);
require('fs').writeFileSync('${BASE_DIR}/2_sentences.txt', lines.join('\n'));
console.log('ğŸ“ 2_sentences.txt:', sentences.length, 'sentences');
"

# Auto-mark silence â†’ 2_auto_selected.json
node -e "
const words = require('${BASE_DIR}/1_subtitles_words.json');
const selected = [];
words.forEach((w, i) => {
  if (w.isGap && (w.end - w.start) >= 0.5) selected.push(i);
});
require('fs').writeFileSync('${BASE_DIR}/2_auto_selected.json', JSON.stringify(selected, null, 2));
console.log('ğŸ”‡ 2_auto_selected.json: â‰¥0.5sé™éŸ³', selected.length, 'æ®µ');
"

# Step 4b: AI å£è¯¯åˆ†æ
echo ""
echo "â•â•â• æ­¥éª¤ 4b: AI å£è¯¯åˆ†æ â•â•â•"
RULES_DIR="$(cd "$(dirname "$0")/å‰ªå£æ’­/ç”¨æˆ·ä¹ æƒ¯" && pwd)"

# Build rules context
RULES_CONTEXT=""
for rule_file in "$RULES_DIR"/[1-9]*.md; do
  RULES_CONTEXT+="$(cat "$rule_file")"$'\n\n'
done

# Build prompt for AI analysis
AI_PROMPT="ä½ æ˜¯è§†é¢‘å£è¯¯åˆ†æä¸“å®¶ã€‚æ ¹æ®ä»¥ä¸‹è§„åˆ™ï¼Œåˆ†æ readable.txt å’Œ sentences.txtï¼Œæ‰¾å‡ºæ‰€æœ‰åº”è¯¥åˆ é™¤çš„ç‰‡æ®µã€‚

## è§„åˆ™
${RULES_CONTEXT}

## readable.txtï¼ˆidx|å†…å®¹|æ—¶é—´èŒƒå›´ï¼‰
$(cat "${BASE_DIR}/2_readable.txt")

## sentences.txtï¼ˆå¥å·|startIdx-endIdx|å¥å­æ–‡æœ¬ï¼‰
$(cat "${BASE_DIR}/2_sentences.txt")

## å½“å‰å·²æ ‡è®°çš„é™éŸ³æ®µï¼ˆidx åˆ—è¡¨ï¼‰
$(cat "${BASE_DIR}/2_auto_selected.json")

## è¾“å‡ºè¦æ±‚

åˆ†æå®Œæˆåï¼Œè¾“å‡ºä¸€ä¸ª JSON æ•°ç»„ï¼ŒåŒ…å«æ‰€æœ‰åº”è¯¥**æ–°å¢**åˆ é™¤çš„ idxï¼ˆä¸è¦åŒ…å«å·²åœ¨ auto_selected.json ä¸­çš„é™éŸ³æ®µï¼‰ã€‚

æ ¼å¼ï¼šçº¯ JSON æ•°ç»„ï¼Œä¸è¦ä»£ç å›´æ ï¼Œä¸è¦è§£é‡Šã€‚
ä¾‹å¦‚ï¼š[12, 13, 14, 28, 29, 30]

æ¯ä¸ª idx å¯¹åº” readable.txt ä¸­çš„ idx å€¼ï¼ˆç¬¬ä¸€åˆ—ï¼‰ã€‚å¦‚æœè¦åˆ æ•´å¥ï¼Œåˆ—å‡ºå¥å­èŒƒå›´å†…çš„æ‰€æœ‰ idxã€‚

é‡è¦ï¼š
- è¡Œå· â‰  idxï¼Œç”¨ readable.txt ç¬¬ä¸€åˆ—çš„ idx å€¼
- åˆ å‰ä¿åï¼šåè¯´çš„é€šå¸¸æ›´å®Œæ•´
- æ®‹å¥è¦æ•´å¥åˆ é™¤ï¼ˆstartIdx åˆ° endIdx çš„æ‰€æœ‰ idxï¼‰
- ä¸è¦åˆ é™¤æ­£å¸¸å†…å®¹ï¼Œå®å¯æ¼åˆ ä¸å¯è¯¯åˆ "

echo "$AI_PROMPT" | claude -p --dangerously-skip-permissions --output-format text > "${BASE_DIR}/2_ai_analysis_raw.txt" 2>/dev/null

# Parse AI output: extract JSON array, merge with auto_selected
node -e "
const fs = require('fs');
const autoSelected = JSON.parse(fs.readFileSync('${BASE_DIR}/2_auto_selected.json', 'utf8'));

// Extract JSON array from AI output
let raw = fs.readFileSync('${BASE_DIR}/2_ai_analysis_raw.txt', 'utf8').trim();
// Strip code fences if present
raw = raw.replace(/^\`\`\`[a-z]*\n?/m, '').replace(/\n?\`\`\`\s*$/m, '').trim();

let aiIdx = [];
try {
  aiIdx = JSON.parse(raw);
  if (!Array.isArray(aiIdx)) aiIdx = [];
  // Filter to valid integers only
  aiIdx = aiIdx.filter(x => Number.isInteger(x) && x >= 0);
} catch(e) {
  console.error('âš ï¸  AI åˆ†æè¾“å‡ºè§£æå¤±è´¥ï¼Œä»…ä½¿ç”¨é™éŸ³æ ‡è®°');
  console.error('Raw output:', raw.slice(0, 200));
}

// Merge and deduplicate
const merged = [...new Set([...autoSelected, ...aiIdx])].sort((a,b) => a - b);
fs.writeFileSync('${BASE_DIR}/2_auto_selected.json', JSON.stringify(merged, null, 2));
console.log('ğŸ¤– AI å£è¯¯åˆ†æ: æ–°å¢', aiIdx.length, 'ä¸ªæ ‡è®°');
console.log('ğŸ“Š åˆå¹¶åæ€»è®¡:', merged.length, 'ä¸ªåˆ é™¤æ ‡è®° (é™éŸ³', autoSelected.length, '+ AI', aiIdx.length, ')');
"

# Step 5: Generate review page
# generate_review.js writes review.html and audio.mp3 to cwd ($BASE_DIR)
echo ""
echo "â•â•â• æ­¥éª¤ 5: ç”Ÿæˆå®¡æ ¸ç½‘é¡µ â•â•â•"
node "$SCRIPT_DIR/generate_review.js" \
  "${BASE_DIR}/1_subtitles_words.json" \
  "${BASE_DIR}/2_auto_selected.json" \
  "${BASE_DIR}/1_audio.mp3"
mv "${BASE_DIR}/review.html" "${BASE_DIR}/3_review.html"

if [ "$NO_SERVER" = true ]; then
  echo ""
  echo "â•â•â• æ­¥éª¤ 6: ç›´æ¥å‰ªè¾‘ï¼ˆè·³è¿‡å®¡æ ¸ï¼‰â•â•â•"

  # Convert idx list to time segments â†’ 3_delete_segments.json
  node -e "
  const words = require('${BASE_DIR}/1_subtitles_words.json');
  const selected = require('${BASE_DIR}/2_auto_selected.json');
  const segs = [];
  for (const idx of selected) {
    const w = words[idx];
    if (w) segs.push({ start: w.start, end: w.end });
  }
  segs.sort((a, b) => a.start - b.start);
  const merged = [];
  for (const seg of segs) {
    if (merged.length && seg.start <= merged[merged.length-1].end + 0.05) {
      merged[merged.length-1].end = Math.max(merged[merged.length-1].end, seg.end);
    } else merged.push({...seg});
  }
  require('fs').writeFileSync('${BASE_DIR}/3_delete_segments.json', JSON.stringify(merged, null, 2));
  console.log('âœ‚ï¸ ', merged.length, 'segments,', merged.reduce((s,x) => s + x.end - x.start, 0).toFixed(1) + 's to delete');
  "

  bash "$SCRIPT_DIR/cut_video.sh" "$VIDEO_PATH" "${BASE_DIR}/3_delete_segments.json" "${BASE_DIR}/3_output_cut.mp4"
else
  echo ""
  echo "â•â•â• æ­¥éª¤ 6: å¯åŠ¨å®¡æ ¸æœåŠ¡å™¨ â•â•â•"
  echo "ğŸŒ http://localhost:8899/3_review.html"
  echo "   æ’­æ”¾ â†’ ç¡®è®¤ â†’ ç‚¹å‡»ã€Œæ‰§è¡Œå‰ªè¾‘ã€"
  echo ""
  node "$SCRIPT_DIR/review_server.js" 8899 "$VIDEO_PATH"
fi
